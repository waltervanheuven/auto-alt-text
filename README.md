# Auto-Alt-Text

Automatically create `Alt Text` for images and other objects in Powerpoint presentations using Multimodal Large Language Models (MLLM) or Visual-Language (VL) pre-trained models. The Python script will create a text file with the generated `Alt Text` as well as apply these to the images and objects in the PowerPoint file and save the updated Powerpoint to a new file.

The script currently supports the following models:

- [Qwen-VL](https://github.com/QwenLM/Qwen-VL)
- [Cog-VL](https://github.com/THUDM/CogVLM)
- [Kosmos-2](https://github.com/microsoft/unilm/tree/master/kosmos-2)
- [OpenCLIP](https://github.com/mlfoundations/open_clip)
- [GPT-4V](https://openai.com/research/gpt-4v-system-card)
- [LLaVA](https://llava-vl.github.io)

All models, except GPT-4V, run locally. GPT-4V requires API access. By default, images are resized so that width and height are maximum 500 pixels before inference. Note that to use the [Qwen-VL](https://github.com/QwenLM/Qwen-VL) model (int 4), requires a computer with an NVIDIA RTX A4000 or better. The [Cog-VL](https://github.com/THUDM/CogVLM) model is not yet working.

## Setup

### macOS/Linux

Install latest Python 3.11 on macOS using [brew](https://brew.sh).

```sh
git clone https://github.com/waltervanheuven/auto-alt-text.git
cd auto-alt-text

python3 -m venv venv
source venv/bin/activate

pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

To generate `Alt Text` for Windows Metafile (WMF) images in Powerpoint on macOS and Linux, the script needs [LibreOffice](https://www.libreoffice.org) to convert WMF to a bitmap format. On macOS use [brew](https://brew.sh) to install LibreOffice. Furthermore, for additional functionality install [qpdf](https://github.com/qpdf/qpdf) and [ImageMagick](https://imagemagick.org).

```sh
brew install libreoffice
brew install qpdf
brew install imagemagick
```

For cuda support on Linux, follow instructions on the [PyTorch website](https://pytorch.org/get-started/locally/) to install torch with cuda support.

### Windows

Install latest Python 3.11 on Windows using, for example, [scoop](https://scoop.sh).

```sh
git clone https://github.com/waltervanheuven/auto-alt-text.git
cd auto-alt-text

python311 -m venv venv
.\venv\Scripts\activate

python -m pip install --upgrade pip setuptools wheel
python -m pip install -r .\requirements.txt

# for cuda support install torch (cuda 12.1)
python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

To generate `Alt Text` for Windows Metafile (WMF) images in Powerpoint on Windows, the script needs [ImageMagick](https://imagemagick.org) to convert WMF to a bitmap format. Use [scoop](https://scoop.sh) to install imagemagick.

```sh
scoop install main/imagemagick
scoop install main/qpdf
```

## Generate accessibility report

Show current alt text of objects (e.g. images, shapes, group shapes) in a Powerpoint file and generate an alt text accessibility report. A tab-delimited text file is created with the alt text of each object in the Powerpoint file.

```sh
python source/auto_alt_text.py pptx/test1.pptx --report
# output is written to `pptx/test1.txt`
```

## Kosmos-2

Example command for using [Kosmos-2](https://github.com/microsoft/unilm/tree/master/kosmos-2) to generate descriptions of images in Powerpoint files. Script will download the Komos-2 model (~6.66GB).

```sh
# generate alt text for images in Powerpoint file based on text generated by Kosmos-2
# note that all images in the powerpoint files are saved separately in a folder
# Powerpoint file with the alt texts will be saved to '<filename>_kosmos2.pptx'
python source/auto_alt_text.py pptx/test1.pptx --model kosmos-2

# custom prompt to get brief image descriptions
python source/auto_alt_text.py pptx/test1.pptx --model kosmos-2 --prompt "<grounding>An image of"
```

## Qwen-VL

Example command for using [Qwen-VL](https://github.com/QwenLM/Qwen-VL) to generate descriptions of images in Powerpoint files. Script will download the Qwen-VL-Chat-Int4 model (~9.75GB).

Using this model requires an NVIDEA GPU. Only tested with an RTX A4000 GPU on Windows.

```sh
# generate alt text for images in Powerpoint file based on text generated by Qwen-VL
# note that all images in the powerpoint files are saved separately in a folder
# Powerpoint file with the alt texts will be saved to '<filename>_kosmos2.pptx'
python source/auto_alt_text.py pptx/test1.pptx --model qwen-vl

# custom prompt to get brief image descriptions
python source/auto_alt_text.py pptx/test1.pptx --model qwen-vl --prompt "What is the key information illustrated in this image"
```

## OpenCLIP

The Python script can also use [OpenCLIP](https://github.com/mlfoundations/open_clip) to generate descriptions of images in Powerpoint files. There are many OpenCLIP models and pretrained models that you can use. To find out the available models, use `--show_openclip_models`. The default model is `coca_ViT-L-14` and the pretrained model is `mscoco_finetuned_laion2B-s13B-b90k` (~2.55Gb model file will be downloaded).

```sh
# generate alt text for images in Powerpoint file based on text generated by OpenCLIP
# note that all images in the powerpoint files are saved separately in a folder
# Powerpoint file with the alt texts will be saved to '<filename>_openclip.pptx'
python source/auto_alt_text.py pptx/test1.pptx --model openclip

# list available OpenCLIP models
python source/auto_alt_text.py pptx/test1.pptx --show_openclip_models

# specify specific OpenCLIP model and pretained model
python source/auto_alt_text.py pptx/test1.pptx --model openclip --openclip_model coca_ViT-L-14 --openclip_pretrained mscoco_finetuned_laion2B-s13B-b90k
```

## GPT-4V

To use [GPT-4V](https://openai.com/research/gpt-4v-system-card) you need to have [API access](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4). Images will be send to OpenAI servers for inference. Costs for using the API depend on the size and number the images. API access [pricing information](https://openai.com/pricing#language-models). The script uses the OPENAI_API_KEY environment variable. Information how to set/add this variable can be found in the [OpenAI quickstart docs](https://platform.openai.com/docs/quickstart?context=python).

```sh
# generate alt text for images in Powerpoint file based on text generated by GPT-4V
# note that all images in the powerpoint files are saved separately in a folder
# Powerpoint file with the alt texts will be saved to '<filename>_gpt4v.pptx'
python source/auto_alt_text.py pptx/test1.pptx --model gpt-4v

# custom prompt
python source/auto_alt_text.py pptx/test1.pptx --model gpt-4v --prompt "Describe clearly in two sentences"
```

## LLaVA

If you want to use LLaVA to generate image descriptions, you need to set up a LLaVA server. A fast implementation of LLaVA is available through [llama.cpp](https://github.com/ggerganov/llama.cpp).

Steps to set up a local LLaVA server:

```sh
# clone llama.cpp repository in a tmp folder
mkdir tmp
cd tmp
git clone https://github.com/ggerganov/llama.cpp.git

# build
cd llama.cpp
make

# create folder `llava` in main folder `auto-alt-text`
cd ..
mkdir llava
mkdir llava/models
```

Copy `server` from the `tmp/llama.cpp/` folder to the `llava` folder. For Metal on macOS also copy `ggml-metal.metal` that can be found in `tmp/llama.cpp/` to the folder `llava`.

Models for [LLaVA](https://llava-vl.github.io) can be found on huggingface: [https://huggingface.co/mys/ggml_llava-v1.5-7b/tree/main](https://huggingface.co/mys/ggml_llava-v1.5-7b/tree/main)

Download `ggml-model-q5_k.gguf` and `mmproj-model-f16.gguf` and move the files to the folder `models` in the folder `llava`.

### Start LLaVA server

```sh
./llava/server -t 4 -c 4096 -ngl 50 -m llava/models/ggml-model-q5_k.gguf --host 0.0.0.0 --port 8007 --mmproj llava/models/mmproj-model-f16.gguf
```

### Example of using LLaVA

```sh
# generate alt text for images in Powerpoint file based on text generated by LLaVA
# note that all images in the powerpoint files are saved separately in a folder
# Powerpoint file with the alt texts will be saved to '<filename>_llava.pptx'
python source/auto_alt_text.py pptx/test1.pptx --model llava

# specify a different prompt
python source/auto_alt_text.py pptx/test1.pptx --model llava --prompt "Describe in simple words using maximal 125 characters"
```

## Edit generated alt texts and apply to Powerpoint file

The generated alt texts are saved to a text file so that these it can be edited. You can apply the edited alt texts in the file to the powerpoint file using the option `--replace`. The Powerpoint file is saved as `<filename>_alt_text.pptx`.

```sh
python source/auto_alt_text.py pptx/test1.pptx --replace pptx/test1_kosmos-2_edited.txt
```

## Help

Add `--help` to show command line options.

```sh
python source/auto_alt_text.py --help
```

```txt
usage: auto_alt_text.py [-h] [--report] [--model MODEL] [--server SERVER] [--port PORT] [--show_openclip_models] [--openclip_model OPENCLIP_MODEL] [--openclip_pretrained OPENCLIP_PRETRAINED] [--resize RESIZE]
                        [--prompt PROMPT] [--save] [--replace REPLACE] [--remove_presenter_notes] [--export_slides] [--debug]
                        file

Add alt-text automatically to images and objects in Powerpoint

positional arguments:
  file                  Powerpoint file

options:
  -h, --help            show this help message and exit
  --report              flag to generate alt text report
  --model MODEL         kosmos-2, openclip, llava, or gpt-4v
  --server SERVER       LLaVA server URL, default=http://localhost
  --port PORT           LLaVA server port, default=8007
  --show_openclip_models
                        show OpenCLIP models and pretrained models
  --openclip_model OPENCLIP_MODEL
                        OpenCLIP model
  --openclip_pretrained OPENCLIP_PRETRAINED
                        OpenCLIP pretrained model
  --resize RESIZE       resize image to same width and height in pixels, default:500, use 0 to disable resize
  --prompt PROMPT       custom prompt
  --save                flag to save powerpoint file with updated alt texts
  --replace REPLACE     replace alt texts in pptx with those specified in file
  --remove_presenter_notes
                        remove all presenter notes
  --export_slides       export pptx slides to png images
  --debug               flag for debugging
```

## Known issues

- LLaVA inference is not working properly when image is resized, use `--resize 0` to disable image resizing.

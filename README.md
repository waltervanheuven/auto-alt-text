# Auto-Alt-Text

Automatically create alt-text for images in Powerpoint files using [LLaVA](https://llava-vl.github.io) or [OpenCLIP](https://github.com/mlfoundations/open_clip).

## Setup

```sh
python3 -m venv venv
source venv/bin/activate

pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

Show current alt text of images in a Powerpoint file. Python script also creates a `txt` file with the alt text of each image in the Powerpoint file.

```sh
python source/auto-alt-text-pptx.py tmp/test.pptx

# output is also written to `tmp/test.txt`
```

## LLaVA

If you want to use LLaVA to generate image descriptions, you need to set up a LLaVA server. An implementation of LLaVA is available in [llama.cpp](https://github.com/ggerganov/llama.cpp).

Steps to set up a local LLaVA server:

```sh
# clone llama.cpp repository
git clone https://github.com/ggerganov/llama.cpp.git

# build
make

# create folder `llama.cpp` in main folder `auto-alt-text`
mkdir llama.cpp
mkdir llama.cpp/models
```

Copy `server` from `llama.cpp` directory to `llama.cpp` within the folder `auto-alt-text`. For Metal on macOS also copy `ggml-metal.metal` to the folder `llama.cpp`.

Models for [LLaVA](https://llava-vl.github.io) can be found on huggingface: [https://huggingface.co/mys/ggml_llava-v1.5-7b/tree/main](https://huggingface.co/mys/ggml_llava-v1.5-7b/tree/main)

Download `ggml-model-q5_k.gguf` and `mmproj-model-f16.gguf` and move the files to the folder `models` in the folder `llama.cpp`.

Start local server:

```sh
./llama.cpp/server -t 4 -c 4096 -ngl 50 -m llama.cpp/models/ggml-model-q5_k.gguf --host 0.0.0.0 --port 8007 --mmproj llama.cpp/models/mmproj-model-f16.gguf
```

```sh
# add alt text based on text generated by LLaVA
# note that all images in the powerpoint files are saved separately 
# and a new powerpoint file is saved with the new alt texts as '<name>_alt_text.pptx'
python source/auto-alt-text-pptx.py tmp/test.pptx --add --type llava

# specify a different prompt
python source/auto-alt-text-pptx.py tmp/test.pptx --add --type llava --prompt "Describe in simple words using maximal 125 characters"
```

## OpenCLIP

The python script can also use [OpenCLIP](https://github.com/mlfoundations/open_clip) to generate descriptions of images in Powerpoint files.

```sh
# only show alt text already available
python source/auto-alt-text-pptx.py tmp/test.pptx

# add alt text to images based on text generated by OpenCLIP
# note that all images in the powerpoint files are saved separately 
# and a new powerpoint file is saved with the new alt text as '<name>_alt_text.pptx'
python source/auto-alt-text-pptx.py tmp/test.pptx --type openclip --add

# specify specific OpenCLIP model and pretained model
python source/auto-alt-text-pptx.py tmp/test.pptx --type openclip --add --model coca_ViT-L-14 --pretrained mscoco_finetuned_laion2B-s13B-b90k
```
